{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 34, "column": 0}, "map": {"version":3,"sources":["file:///Users/arnaudpfu/nextjs-expo-boilerplate/main_august/ai/apps/nextjs-example/app/api/chat/route.ts"],"sourcesContent":["import { openai, createOpenAI } from \"@ai-sdk/openai\";\nimport { streamText, convertToModelMessages, type UIMessage } from \"ai\";\n\nconst groq = createOpenAI({\n  apiKey: process.env.GROQ_API_KEY ?? '',\n  baseURL: 'https://api.groq.com/openai/v1',\n});\n\n\nexport async function POST(req: Request) {\n  const { messages }: { messages: UIMessage[] } = await req.json();\n\n  const result = streamText({\n    // model: openai.responses(\"gpt-5-nano\"),\n    model: groq('llama-3.3-70b-versatile'),\n    messages: await convertToModelMessages(messages),\n    providerOptions: {\n      openai: {\n        reasoningEffort: \"low\",\n        reasoningSummary: \"auto\",\n      },\n    },\n  });\n\n  return result.toUIMessageStreamResponse({\n    sendReasoning: true,\n  });\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,MAAM,OAAO,IAAA,iQAAY,EAAC;IACxB,QAAQ,QAAQ,GAAG,CAAC,YAAY,IAAI;IACpC,SAAS;AACX;AAGO,eAAe,KAAK,GAAY;IACrC,MAAM,EAAE,QAAQ,EAAE,GAA8B,MAAM,IAAI,IAAI;IAE9D,MAAM,SAAS,IAAA,yOAAU,EAAC;QACxB,yCAAyC;QACzC,OAAO,KAAK;QACZ,UAAU,MAAM,IAAA,qPAAsB,EAAC;QACvC,iBAAiB;YACf,QAAQ;gBACN,iBAAiB;gBACjB,kBAAkB;YACpB;QACF;IACF;IAEA,OAAO,OAAO,yBAAyB,CAAC;QACtC,eAAe;IACjB;AACF"}}]
}